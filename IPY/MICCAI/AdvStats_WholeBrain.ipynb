{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os\n",
    "import trako as TKO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TKO.Util.loadvtp('/home/haehn/Dropbox/TRAKODATA/WholeBrain/RealTractDataIncludingTensorsAndScalars.vtk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = TKO.Util.loadvtp('/home/haehn/Dropbox/TRAKODATA/WholeBrain/RealTractDataIncludingTensorsAndScalars.vtk_restored_configqbi10.vtp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FreeWater', 'tensor2', 'tensor1', 'EstimatedUncertainty']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['scalar_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FreeWater', 'tensor2', 'tensor1', 'EstimatedUncertainty']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['scalar_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5650084,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b['scalars'][3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT='/'\n",
    "BLACKLIST = 'tracts_commissural'\n",
    "DATAFOLDER = '/home/haehn/Dropbox/TRAKODATA/WholeBrain_VTK//'\n",
    "# DATAFOLDER = '/home/haehn/Dropbox/TKOTEST/'\n",
    "DATAFOLDER_TKO = DATAFOLDER[:-1]+'_TKO/'\n",
    "DATAFOLDER_RESTORED = DATAFOLDER[:-1]+'_RESTORED/'\n",
    "STATSFOLDER = DATAFOLDER[:-1]+'_STATS/'\n",
    "DATAFOLDER += SUBJECT\n",
    "DATAFOLDER_TKO += SUBJECT\n",
    "DATAFOLDER_RESTORED += SUBJECT\n",
    "STATSFILE = STATSFOLDER+SUBJECT[:-1]+'.p'\n",
    "\n",
    "originalsize = []\n",
    "compressedsize = []\n",
    "number_of_streamlines = []\n",
    "c_time = []\n",
    "d_time = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293.17223715782166\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 10\n",
    "scalarstats = {\n",
    "    \n",
    "}\n",
    "propertystats = {\n",
    "    \n",
    "}\n",
    "counter = 0\n",
    "firstrun = True\n",
    "t0 = time.time()\n",
    "# for f in os.listdir(DATAFOLDER):\n",
    "\n",
    "i_poly = a\n",
    "r_poly = b\n",
    "\n",
    "#     i_poly = TKO.Util.loadvtp(input)\n",
    "i_scalars = i_poly['scalars']\n",
    "i_nscalars = i_poly['scalar_names']\n",
    "i_properties = i_poly['properties']\n",
    "i_nproperties = i_poly['property_names']\n",
    "\n",
    "#     r_poly = TKO.Util.loadvtp(restored)\n",
    "r_scalars = r_poly['scalars']\n",
    "r_properties = r_poly['properties']\n",
    "\n",
    "#             print(i_poly['points'])\n",
    "#             print(r_poly['points'])\n",
    "#             print(i_scalars)\n",
    "#             print(r_scalars)\n",
    "\n",
    "if len(i_scalars)==0 or len(r_scalars) == 0:\n",
    "    print('skipped', name)\n",
    "\n",
    "\n",
    "#             if (np.isnan(np.any(i_scalars))):\n",
    "#                 print('NaN', name, i_scalars)\n",
    "#                 continue\n",
    "\n",
    "#             if (np.isnan(np.any(r_scalars))):\n",
    "#                 print('NaN2', name, i_scalars)\n",
    "#                 continue\n",
    "\n",
    "if firstrun:\n",
    "    for i,s in enumerate(i_nscalars):\n",
    "        scalarstats[s] = [0,0,0,0,np.inf,-np.inf]\n",
    "#                     print ('reset')\n",
    "    for i,p in enumerate(i_nproperties):\n",
    "        propertystats[p] = [0,0,0,0,np.inf,-np.inf]\n",
    "\n",
    "    firstrun = False\n",
    "\n",
    "\n",
    "\n",
    "for i,s in enumerate(i_scalars):\n",
    "    c_name = i_nscalars[i]\n",
    "\n",
    "    stats = TKO.Util.error(i_scalars[i], r_scalars[i])\n",
    "#                 print(stats)\n",
    "\n",
    "#                 if (np.isnan(stats[0][0])):\n",
    "#                     print(input, counter, r_scalars)\n",
    "\n",
    "    scalarstats[c_name][0] += stats[0][0]\n",
    "    scalarstats[c_name][1] += stats[0][1]\n",
    "    scalarstats[c_name][2] += stats[0][2]\n",
    "    scalarstats[c_name][3] += stats[0][3]\n",
    "    scalarstats[c_name][4] = min(np.min(i_scalars[i]),scalarstats[c_name][4] )\n",
    "    scalarstats[c_name][5] = max(np.max(i_scalars[i]),scalarstats[c_name][5] )\n",
    "\n",
    "for i,s in enumerate(i_properties):\n",
    "    c_name = i_nproperties[i]\n",
    "\n",
    "    stats = TKO.Util.error(i_properties[i], r_properties[i])\n",
    "#                 print(stats)\n",
    "\n",
    "#                 if (np.isnan(stats[0][0])):\n",
    "#                     print(input, counter, r_scalars)\n",
    "\n",
    "    propertystats[c_name][0] += stats[0][0]\n",
    "    propertystats[c_name][1] += stats[0][1]\n",
    "    propertystats[c_name][2] += stats[0][2]\n",
    "    propertystats[c_name][3] += stats[0][3]\n",
    "    propertystats[c_name][4] = min(np.min(i_properties[i]),propertystats[c_name][4] )\n",
    "    propertystats[c_name][5] = max(np.max(i_properties[i]),propertystats[c_name][5] )\n",
    "\n",
    "counter += 1\n",
    "\n",
    "            \n",
    "# normalize\n",
    "for s in scalarstats.keys():\n",
    "    for i,v in enumerate(scalarstats[s]):\n",
    "        if i > 3:\n",
    "            continue\n",
    "        scalarstats[s][i] /= counter\n",
    "for s in propertystats.keys():\n",
    "    for i,v in enumerate(propertystats[s]):\n",
    "        if i > 3:\n",
    "            continue\n",
    "        propertystats[s][i] /= counter\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FreeWater': [0.0,\n",
       "  3.0547380447387695e-05,\n",
       "  1.4210282643034589e-05,\n",
       "  9.33843148231972e-06,\n",
       "  0.0,\n",
       "  1.0],\n",
       " 'tensor2': [1.5375793083194367e-08,\n",
       "  4.924756353830162e-07,\n",
       "  2.8949870056749205e-07,\n",
       "  5.903690336594991e-08,\n",
       "  -0.0013220137,\n",
       "  0.0042674122],\n",
       " 'tensor1': [2.1554678042434716e-08,\n",
       "  3.8895998955013056e-07,\n",
       "  2.2696508494846057e-07,\n",
       "  4.628169492093548e-08,\n",
       "  -0.0013191047,\n",
       "  0.0030630874],\n",
       " 'EstimatedUncertainty': [0.0,\n",
       "  0.5986328125,\n",
       "  0.29056376218795776,\n",
       "  0.1768338829278946,\n",
       "  0.03316625,\n",
       "  19567.16]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalarstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mean= np.round(scalarstats['tensor2'][2],10),np.round(scalarstats['tensor2'][3],10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.895e-07, 5.9e-08)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreeWater ($N$, range:  0.0-1.0 ) \\\\\n",
      "tensor2 ($N$, range:  -0.0013220137-0.0042674122 ) \\\\\n",
      "tensor1 ($N$, range:  -0.0013191047-0.0030630874 ) \\\\\n",
      "EstimatedUncertainty ($N$, range:  0.03316625-19567.16 ) \\\\\n",
      "1.42103e-05$\\pm$9.3384e-06 \\\\\n",
      "2.895e-07$\\pm$5.9e-08 \\\\\n",
      "2.27e-07$\\pm$4.63e-08 \\\\\n",
      "0.2905637622$\\pm$0.1768338829 \\\\\n"
     ]
    }
   ],
   "source": [
    "prec = 10\n",
    "for p in scalarstats.keys():\n",
    "    ranger = np.round(scalarstats[p][4],prec),np.round(scalarstats[p][5],prec)\n",
    "    mean= np.round(scalarstats[p][2],prec),np.round(scalarstats[p][3],prec)\n",
    "    ranger_str = str(str(np.round(ranger[0],prec))+'-'+str(np.round(ranger[1],prec)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(p, '($N$, range: ',ranger_str, ') \\\\\\\\')\n",
    "for p in scalarstats.keys():\n",
    "    ranger = np.round(scalarstats[p][4],prec),np.round(scalarstats[p][5],prec)\n",
    "    mean= np.round(scalarstats[p][2],prec),np.round(scalarstats[p][3],prec)\n",
    "    ranger_str = str(str(np.round(ranger[0],prec))+'-'+str(np.round(ranger[1],prec)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(mean_str , '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in propertystats.keys():\n",
    "    ranger = np.round(propertystats[p][4],3),np.round(propertystats[p][5],3)\n",
    "    mean= np.round(propertystats[p][2],3),np.round(propertystats[p][3],3)\n",
    "    ranger_str = str(str(np.round(ranger[0],2))+'-'+str(np.round(ranger[1],2)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(p, '($N$, range: ',ranger_str, ') \\\\\\\\')\n",
    "for p in propertystats.keys():\n",
    "    ranger = np.round(propertystats[p][4],3),np.round(propertystats[p][5],3)\n",
    "    mean= np.round(propertystats[p][2],3),np.round(propertystats[p][3],3)\n",
    "    ranger_str = str(str(np.round(ranger[0],2))+'-'+str(np.round(ranger[1],2)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(mean_str , '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressedsize = 256311269\n",
    "originalsize = 543022588\n",
    "\n",
    "c_ratio = (1-float(compressedsize)/float(originalsize))*100\n",
    "c_factor = float(originalsize) / float(compressedsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.799"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(c_ratio,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.119"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(c_factor,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(compressedsize/1000000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
