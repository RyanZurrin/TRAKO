{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle,os,time\n",
    "import trako as TKO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECT='/'\n",
    "BLACKLIST = 'tracts_commissural'\n",
    "DATAFOLDER = '/home/haehn/Dropbox/TRAKODATA/AnatomicalTracts/'\n",
    "# DATAFOLDER = '/home/haehn/Dropbox/TKOTEST/'\n",
    "DATAFOLDER_TKO = DATAFOLDER[:-1]+'_TKO/'\n",
    "DATAFOLDER_RESTORED = DATAFOLDER[:-1]+'_RESTORED/'\n",
    "STATSFOLDER = DATAFOLDER[:-1]+'_STATS/'\n",
    "DATAFOLDER += SUBJECT\n",
    "DATAFOLDER_TKO += SUBJECT\n",
    "DATAFOLDER_RESTORED += SUBJECT\n",
    "STATSFILE = STATSFOLDER+SUBJECT[:-1]+'.p'\n",
    "\n",
    "originalsize = []\n",
    "compressedsize = []\n",
    "number_of_streamlines = []\n",
    "c_time = []\n",
    "d_time = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = []\n",
    "for f in os.listdir(DATAFOLDER):\n",
    "\n",
    "        if f.endswith('.vtp') and not 'restored' in f:\n",
    "            input = os.path.join(DATAFOLDER, f)\n",
    "            input_size.append(os.path.getsize(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_size = []\n",
    "for f in os.listdir(DATAFOLDER):\n",
    "\n",
    "        if f.endswith('_compressed_configqbi10_binary.tko.glb'):\n",
    "            input = os.path.join(DATAFOLDER, f)\n",
    "            compressed_size.append(os.path.getsize(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32882748"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13428576"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(compressed_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.52129864692688\n"
     ]
    }
   ],
   "source": [
    "THRESHOLD = 10\n",
    "scalarstats = {\n",
    "    \n",
    "}\n",
    "propertystats = {\n",
    "    \n",
    "}\n",
    "counter = 0\n",
    "firstrun = True\n",
    "t0 = time.time()\n",
    "for f in os.listdir(DATAFOLDER):\n",
    "\n",
    "        if f.endswith('.vtp') and not 'restored' in f:\n",
    "            input = os.path.join(DATAFOLDER, f)\n",
    "            \n",
    "            \n",
    "            \n",
    "#             compressed = input.replace('.vtp','.tko')\n",
    "            restored = input.replace('.vtp', '.vtp_restored_configqbi10.vtp')\n",
    "            \n",
    "            i_poly = TKO.Util.loadvtp(input)\n",
    "            i_scalars = i_poly['scalars']\n",
    "            i_nscalars = i_poly['scalar_names']\n",
    "            i_properties = i_poly['properties']\n",
    "            i_nproperties = i_poly['property_names']\n",
    "            \n",
    "            r_poly = TKO.Util.loadvtp(restored)\n",
    "            r_scalars = r_poly['scalars']\n",
    "            r_properties = r_poly['properties']\n",
    "            \n",
    "#             print(i_poly['points'])\n",
    "#             print(r_poly['points'])\n",
    "#             print(i_scalars)\n",
    "#             print(r_scalars)\n",
    "\n",
    "            if len(i_scalars)==0 or len(r_scalars) == 0:\n",
    "                print('skipped', name)\n",
    "                continue\n",
    "                \n",
    "#             if (np.isnan(np.any(i_scalars))):\n",
    "#                 print('NaN', name, i_scalars)\n",
    "#                 continue\n",
    "                \n",
    "#             if (np.isnan(np.any(r_scalars))):\n",
    "#                 print('NaN2', name, i_scalars)\n",
    "#                 continue\n",
    "            \n",
    "            if firstrun:\n",
    "                for i,s in enumerate(i_nscalars):\n",
    "                    scalarstats[s] = [0,0,0,0,np.inf,-np.inf]\n",
    "#                     print ('reset')\n",
    "                for i,p in enumerate(i_nproperties):\n",
    "                    propertystats[p] = [0,0,0,0,np.inf,-np.inf]\n",
    "                \n",
    "                firstrun = False\n",
    "    \n",
    "    \n",
    "            \n",
    "            for i,s in enumerate(i_scalars):\n",
    "                c_name = i_nscalars[i]\n",
    "            \n",
    "                stats = TKO.Util.error(i_scalars[i], r_scalars[i])\n",
    "#                 print(stats)\n",
    "\n",
    "#                 if (np.isnan(stats[0][0])):\n",
    "#                     print(input, counter, r_scalars)\n",
    "\n",
    "                scalarstats[c_name][0] += stats[0][0]\n",
    "                scalarstats[c_name][1] += stats[0][1]\n",
    "                scalarstats[c_name][2] += stats[0][2]\n",
    "                scalarstats[c_name][3] += stats[0][3]\n",
    "                scalarstats[c_name][4] = min(np.min(i_scalars[i]),scalarstats[c_name][4] )\n",
    "                scalarstats[c_name][5] = max(np.max(i_scalars[i]),scalarstats[c_name][5] )\n",
    "\n",
    "            for i,s in enumerate(i_properties):\n",
    "                c_name = i_nproperties[i]\n",
    "            \n",
    "                stats = TKO.Util.error(i_properties[i], r_properties[i])\n",
    "#                 print(stats)\n",
    "\n",
    "#                 if (np.isnan(stats[0][0])):\n",
    "#                     print(input, counter, r_scalars)\n",
    "\n",
    "                propertystats[c_name][0] += stats[0][0]\n",
    "                propertystats[c_name][1] += stats[0][1]\n",
    "                propertystats[c_name][2] += stats[0][2]\n",
    "                propertystats[c_name][3] += stats[0][3]\n",
    "                propertystats[c_name][4] = min(np.min(i_properties[i]),propertystats[c_name][4] )\n",
    "                propertystats[c_name][5] = max(np.max(i_properties[i]),propertystats[c_name][5] )\n",
    "                \n",
    "            counter += 1\n",
    "        if counter > THRESHOLD:\n",
    "            break\n",
    "            \n",
    "# normalize\n",
    "for s in scalarstats.keys():\n",
    "    for i,v in enumerate(scalarstats[s]):\n",
    "        if i > 3:\n",
    "            continue\n",
    "        scalarstats[s][i] /= counter\n",
    "for s in propertystats.keys():\n",
    "    for i,v in enumerate(propertystats[s]):\n",
    "        if i > 3:\n",
    "            continue\n",
    "        propertystats[s][i] /= counter\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EstimatedUncertainty': [0.0,\n",
       "  0.2753684303977273,\n",
       "  0.1347860497507182,\n",
       "  0.080928696827455,\n",
       "  0.031622775,\n",
       "  15233.791],\n",
       " 'tensor2': [2.344598010689031e-08,\n",
       "  1.3793757086039643e-07,\n",
       "  8.731460419333169e-08,\n",
       "  1.781123095476935e-08,\n",
       "  -0.0008659273,\n",
       "  0.0020841828],\n",
       " 'HemisphereLocataion': [0.0, 0.0, 0.0, 0.0, 1.0, 3.0],\n",
       " 'cluster_idx': [0.0,\n",
       "  0.8181818181818182,\n",
       "  0.24584532274382476,\n",
       "  0.3614032346871214,\n",
       "  0,\n",
       "  39],\n",
       " 'tensor1': [2.8291385073037582e-08,\n",
       "  1.7842506462205743e-07,\n",
       "  1.1212859295607235e-07,\n",
       "  2.2736418969770966e-08,\n",
       "  -0.0009526277,\n",
       "  0.0023900766]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalarstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EmbeddingCoordinate': [0.00016411313250004738,\n",
       "  0.0003467026769860902,\n",
       "  0.00026175899917937136,\n",
       "  3.721884670746724e-05,\n",
       "  -4.542453,\n",
       "  3.0473692],\n",
       " 'ClusterNumber': [0.0, 1.0, 0.42374512385046914, 0.47632639176233393, 8, 665],\n",
       " 'EmbeddingColor': [0.0,\n",
       "  1.3765577839755414,\n",
       "  0.8775463746838645,\n",
       "  0.47481806050288583,\n",
       "  0,\n",
       "  180],\n",
       " 'TotalFiberSimilarity': [0.0,\n",
       "  15.903409090909092,\n",
       "  8.019401463595303,\n",
       "  4.754698276519775,\n",
       "  199220.9,\n",
       "  920767.2],\n",
       " 'MeasuredFiberSimilarity': [0.0,\n",
       "  1.517632468180223e-08,\n",
       "  7.408974363313932e-09,\n",
       "  4.543307689659896e-09,\n",
       "  0.0017869201,\n",
       "  0.0026580554]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propertystats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EstimatedUncertainty ($N$, range:  0.031622775-15233.791 ) \\\\\n",
      "tensor2 ($N$, range:  -0.0008659273-0.0020841828 ) \\\\\n",
      "HemisphereLocataion ($N$, range:  1.0-3.0 ) \\\\\n",
      "cluster_idx ($N$, range:  0-39 ) \\\\\n",
      "tensor1 ($N$, range:  -0.0009526277-0.0023900766 ) \\\\\n",
      "0.1347860498$\\pm$0.0809286968 \\\\\n",
      "8.73e-08$\\pm$1.78e-08 \\\\\n",
      "0.0$\\pm$0.0 \\\\\n",
      "0.2458453227$\\pm$0.3614032347 \\\\\n",
      "1.121e-07$\\pm$2.27e-08 \\\\\n"
     ]
    }
   ],
   "source": [
    "prec = 10\n",
    "for p in scalarstats.keys():\n",
    "    ranger = np.round(scalarstats[p][4],prec),np.round(scalarstats[p][5],prec)\n",
    "    mean= np.round(scalarstats[p][2],prec),np.round(scalarstats[p][3],prec)\n",
    "    ranger_str = str(str(np.round(ranger[0],prec))+'-'+str(np.round(ranger[1],prec)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(p, '($N$, range: ',ranger_str, ') \\\\\\\\')\n",
    "for p in scalarstats.keys():\n",
    "    ranger = np.round(scalarstats[p][4],prec),np.round(scalarstats[p][5],prec)\n",
    "    mean= np.round(scalarstats[p][2],prec),np.round(scalarstats[p][3],prec)\n",
    "    ranger_str = str(str(np.round(ranger[0],prec))+'-'+str(np.round(ranger[1],prec)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(mean_str , '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingCoordinate ($N$, range:  -4.542453-3.0473692 ) \\\\\n",
      "ClusterNumber ($N$, range:  8-665 ) \\\\\n",
      "EmbeddingColor ($N$, range:  0-180 ) \\\\\n",
      "TotalFiberSimilarity ($N$, range:  199220.9-920767.25 ) \\\\\n",
      "MeasuredFiberSimilarity ($N$, range:  0.0017869202-0.0026580554 ) \\\\\n",
      "0.000261759$\\pm$3.72188e-05 \\\\\n",
      "0.4237451239$\\pm$0.4763263918 \\\\\n",
      "0.8775463747$\\pm$0.4748180605 \\\\\n",
      "8.0194014636$\\pm$4.7546982765 \\\\\n",
      "7.4e-09$\\pm$4.5e-09 \\\\\n"
     ]
    }
   ],
   "source": [
    "prec = 10\n",
    "for p in propertystats.keys():\n",
    "    ranger = np.round(propertystats[p][4],prec),np.round(propertystats[p][5],prec)\n",
    "    mean= np.round(propertystats[p][2],prec),np.round(propertystats[p][3],prec)\n",
    "    ranger_str = str(str(np.round(ranger[0],prec))+'-'+str(np.round(ranger[1],prec)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(p, '($N$, range: ',ranger_str, ') \\\\\\\\')\n",
    "for p in propertystats.keys():\n",
    "    ranger = np.round(propertystats[p][4],prec),np.round(propertystats[p][5],prec)\n",
    "    mean= np.round(propertystats[p][2],prec),np.round(propertystats[p][3],prec)\n",
    "    ranger_str = str(str(np.round(ranger[0],prec))+'-'+str(np.round(ranger[1],prec)))\n",
    "    mean_str = str(mean[0])+'$\\pm$'+str(mean[1])\n",
    "    print(mean_str , '\\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressedsize = np.sum(compressed_size)\n",
    "originalsize = np.sum(input_size)\n",
    "\n",
    "c_ratio = (1-float(compressedsize)/float(originalsize))*100\n",
    "c_factor = float(originalsize) / float(compressedsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.162"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(c_ratio,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.449"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(c_factor,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.43"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(compressedsize/1000000,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
